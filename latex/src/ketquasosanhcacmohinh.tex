
\section{Kết quả và so sánh các mô hình}

Tất cả các chỉ số dưới đây đều tính trên tập kiểm thử (20\% dữ liệu), sau khi tiền xử lý và tối ưu tham số bằng GridSearchCV trên tập huấn luyện. Các chỉ số chính gồm: accuracy (độ chính xác), recall (độ nhạy), specificity (độ đặc hiệu), với công thức:
\begin{itemize}
    \item \textbf{Accuracy} = $\frac{TP + TN}{TP + TN + FP + FN}$
    \item \textbf{Recall} = $\frac{TP}{TP + FN}$
    \item \textbf{Specificity} = $\frac{TN}{TN + FP}$
\end{itemize}
TP: dự đoán đúng người mắc, TN: đúng người không mắc, FP: dự đoán nhầm mắc, FN: dự đoán nhầm không mắc.

\subsection{Decision Tree}
Mô hình Cây quyết định đạt:
\begin{itemize}
    \item TP = 133, TN = 267, FP = 10, FN = 20
    \item Accuracy $= \frac{133 + 267}{133 + 267 + 10 + 20} = \frac{400}{430} = 0.930$
    \item Recall $= \frac{133}{133 + 20} = \frac{133}{153} = 0.87$
    \item Specificity $= \frac{267}{267 + 10} = \frac{267}{277} = 0.96$
\end{itemize}
Ma trận nhầm lẫn dưới đây cho thấy số lượng dự đoán đúng/sai của mô hình trên tập kiểm thử (TP: đúng người mắc, TN: đúng người không mắc, FP: nhầm mắc, FN: nhầm không mắc).
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{assets/confusion_matrix_decisiontree.png}
    \caption{Ma trận nhầm lẫn Decision Tree}
\end{figure}

\subsection{K-Nearest Neighbors (KNN)}
KNN cho thấy accuracy thay đổi theo số lượng láng giềng K. Khi K=15, mô hình đạt:
\begin{itemize}
    \item TP = 68, TN = 258, FP = 19, FN = 85
    \item Accuracy $= \frac{68 + 258}{68 + 258 + 19 + 85} = \frac{326}{430} = 0.758$
    \item Recall $= \frac{68}{68 + 85} = \frac{68}{153} = 0.44$
    \item Specificity $= \frac{258}{258 + 19} = \frac{258}{277} = 0.93$
\end{itemize}
Biểu đồ dưới đây minh họa sự thay đổi accuracy theo từng giá trị K. Ma trận nhầm lẫn cho thấy KNN ưu tiên dự đoán đúng người không mắc bệnh (specificity cao), nhưng khả năng nhận diện đúng người mắc bệnh còn hạn chế (recall thấp).
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{assets/knn_k_vs_accuracy.png}
    \caption{Độ chính xác KNN theo số lượng láng giềng K}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{assets/confusion_matrix_knn.png}
    \caption{Ma trận nhầm lẫn KNN (K=15)}
\end{figure}

\subsection{Logistic Regression}
Logistic Regression đạt:
\begin{itemize}
    \item TP = 109, TN = 249, FP = 28, FN = 44
    \item Accuracy $= \frac{109 + 249}{109 + 249 + 28 + 44} = \frac{358}{430} = 0.833$
    \item Recall $= \frac{109}{109 + 44} = \frac{109}{153} = 0.71$
    \item Specificity $= \frac{249}{249 + 28} = \frac{249}{277} = 0.90$
\end{itemize}
Ma trận nhầm lẫn cho thấy mô hình cân bằng giữa hai nhóm. Biểu đồ hệ số hồi quy giúp giải thích tác động của từng biến: hệ số dương làm tăng xác suất mắc bệnh, hệ số âm làm giảm xác suất. Các yếu tố lâm sàng và khả năng thực hiện hoạt động thường ngày ảnh hưởng mạnh nhất đến dự đoán.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{assets/confusion_matrix_logreg.png}
    \caption{Ma trận nhầm lẫn Logistic Regression}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{assets/logreg_coefficients.png}
    \caption{Hệ số hồi quy các biến trong Logistic Regression}
\end{figure}

\subsection{Support Vector Machine (SVM)}
SVM với kernel RBF và tuyến tính đạt:
\begin{itemize}
    \item \textbf{Linear kernel:} TP = 109, TN = 246, FP = 31, FN = 44\\
    Accuracy $= \frac{109 + 246}{109 + 246 + 31 + 44} = \frac{355}{430} = 0.826$\\
    Recall $= \frac{109}{109 + 44} = \frac{109}{153} = 0.71$\\
    Specificity $= \frac{246}{246 + 31} = \frac{246}{277} = 0.89$
    \item \textbf{RBF kernel:} TP = 107, TN = 255, FP = 22, FN = 46\\
    Accuracy $= \frac{107 + 255}{107 + 255 + 22 + 46} = \frac{362}{430} = 0.842$\\
    Recall $= \frac{107}{107 + 46} = \frac{107}{153} = 0.70$\\
    Specificity $= \frac{255}{255 + 22} = \frac{255}{277} = 0.92$
\end{itemize}
Ma trận nhầm lẫn dưới đây cho thấy sự khác biệt giữa các kernel. Biểu đồ cột minh họa sự khác biệt accuracy giữa các kernel.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{assets/confusion_matrix_svm_linear.png}
    \caption{Ma trận nhầm lẫn SVM (Linear)}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{assets/confusion_matrix_svm_rbf.png}
    \caption{Ma trận nhầm lẫn SVM (RBF)}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{assets/svm_kernel_compare.png}
    \caption{So sánh accuracy SVM với các kernel}
\end{figure}

\subsection{Tóm tắt kết quả và so sánh}
Bảng dưới đây tổng hợp các chỉ số chính trên tập kiểm thử:
\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|}
        \hline
        	extbf{Mô hình} & \textbf{Accuracy} & \textbf{Recall} & \textbf{Specificity} \\
        \hline
        Decision Tree & 0.930 & 0.87 & 0.96 \\
        KNN (K=15) & 0.758 & 0.44 & 0.93 \\
        Logistic Regression & 0.833 & 0.71 & 0.90 \\
        SVM (Linear) & 0.826 & 0.71 & 0.89 \\
        SVM (RBF) & 0.842 & 0.70 & 0.92 \\
        \hline
    \end{tabular}
    \caption{Bảng tổng hợp kết quả các mô hình trên tập kiểm thử}
\end{table}

	extbf{Kết luận:} Decision Tree vượt trội về accuracy, recall và specificity, phù hợp nhất cho bài toán này. SVM (RBF) và Logistic Regression cũng là lựa chọn tốt khi cần cân bằng giữa các chỉ số hoặc giải thích mô hình. KNN chỉ phù hợp nếu ưu tiên specificity, nhưng recall thấp nên hạn chế dùng khi cần phát hiện bệnh nhân mắc Alzheimer.